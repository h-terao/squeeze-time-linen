{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch"
      ],
      "metadata": {
        "id": "KlbctCkhAxWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install CUDA 11.6\n",
        "%env DEBIAN_FRONTEND=noninteractive\n",
        "\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n",
        "!sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/11.6.2/local_installers/cuda-repo-ubuntu2004-11-6-local_11.6.2-510.47.03-1_amd64.deb\n",
        "!sudo dpkg -i cuda-repo-ubuntu2004-11-6-local_11.6.2-510.47.03-1_amd64.deb\n",
        "!sudo apt-key add /var/cuda-repo-ubuntu2004-11-6-local/7fa2af80.pub\n",
        "\n",
        "!sudo add-apt-repository -y ppa:cloudhan/liburcu6\n",
        "!sudo apt-get update\n",
        "!sudo apt-get -y install liburcu6 cuda-11-6\n",
        "\n",
        "import os\n",
        "\n",
        "%env PATH=/usr/local/cuda-11.6/bin:{os.getenv('PATH')}\n",
        "%env BNB_CUDA_VERSION=116\n",
        "%env CUDA_VERSION=116\n",
        "%env LD_LIBRARY_PATH=/usr/local/cuda-11.6/lib64:{os.environ['LD_LIBRARY_PATH']}\n",
        "!nvcc --version"
      ],
      "metadata": {
        "id": "HUD25Vkau39w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo $PATH"
      ],
      "metadata": {
        "id": "fWGRDTUl1Y9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip uninstall -y torch torchvision torchaudio torchtext\n",
        "!python3 -m pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 timm --extra-index-url https://download.pytorch.org/whl/cu116"
      ],
      "metadata": {
        "id": "LVS-UZNKwotr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> 引用を追加\n",
        "\n"
      ],
      "metadata": {
        "id": "CcSw08K-xCbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install mmaction2 dependencies\n",
        "!pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install mmcv==2.1.0\n",
        "!mim install mmdet\n",
        "!mim install mmpose"
      ],
      "metadata": {
        "id": "dyVkZUI_Av0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleanup directories.\n",
        "!rm -rf mmaction2\n",
        "!rm -rf SqueezeTime\n",
        "\n",
        "!git clone https://github.com/open-mmlab/mmaction2.git\n",
        "!git clone https://github.com/xinghaochen/SqueezeTime.git\n",
        "!cp SqueezeTime/mmaction/models/backbones/SqueezeTime.py mmaction2/mmaction/models/backbones/\n",
        "!cp SqueezeTime/mmaction/models/backbones/SqueezeTime_ava.py mmaction2/mmaction/models/backbones/\n",
        "!cp SqueezeTime/mmaction/models/heads/i2d_head.py mmaction2/mmaction/models/heads/\n",
        "\n",
        "!echo \"from .SqueezeTime import SqueezeTime\" >> mmaction2/mmaction/models/backbones/__init__.py\n",
        "!echo \"from .SqueezeTime_ava import SqueezeTime_ava\" >> mmaction2/mmaction/models/backbones/__init__.py\n",
        "!echo \"from .i2d_head import I2DHead\" >> mmaction2/mmaction/models/heads/__init__.py\n",
        "!echo \"\" > mmaction2/mmaction/models/localizers/drn/__init__.py\n",
        "!pip install ./mmaction2\n"
      ],
      "metadata": {
        "id": "y9Bc8Lt6AwoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flax implementation."
      ],
      "metadata": {
        "id": "KTZeSu18Aphw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flax chex einops"
      ],
      "metadata": {
        "id": "ZS4zx2ygD9fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download PyTorch checkpoints\n",
        "!curl -LO https://github.com/xinghaochen/SqueezeTime/releases/download/ckpts/SqueezeTime_in1k_pretrain.pth\n",
        "!curl -LO https://github.com/xinghaochen/SqueezeTime/releases/download/ckpts/SqueezeTime_K400_71.64.pth\n",
        "!curl -LO https://github.com/xinghaochen/SqueezeTime/releases/download/ckpts/SqueezeTime_K600_76.06.pth\n",
        "!curl -LO https://github.com/xinghaochen/SqueezeTime/releases/download/ckpts/SqueezeTime_HMDB51_65.56.pth\n",
        "# !curl -LO https://github.com/xinghaochen/SqueezeTime/releases/download/ckpts/SqueezeTime-AVA2.1.pth\n",
        "\n",
        "%mkdir ckpts\n",
        "!mv *.pth ckpts/"
      ],
      "metadata": {
        "id": "zQSzDu2ZkMcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYR3_QWg_td-"
      },
      "outputs": [],
      "source": [
        "from typing import Any, Sequence\n",
        "from functools import partial\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from flax import linen\n",
        "import chex\n",
        "import einops\n",
        "\n",
        "ModuleDef = Any\n",
        "\n",
        "\n",
        "def to_2tuple(x: Any | Sequence[Any]) -> tuple[Any, Any]:\n",
        "    if isinstance(x, Sequence):\n",
        "        assert len(x) == 2\n",
        "        return x\n",
        "    return (x, x)\n",
        "\n",
        "\n",
        "def to_padding(padding: int | tuple[int, int] | Sequence[tuple[int, int]]) -> list[tuple[int, int]]:\n",
        "    if isinstance(padding, int):\n",
        "        return [(padding, padding), (padding, padding)]\n",
        "    elif isinstance(padding, tuple) and isinstance(padding[0], int):\n",
        "        return [padding, padding]\n",
        "    else:\n",
        "        assert isinstance(padding, Sequence) and len(padding) == 2\n",
        "        for x in padding:\n",
        "            assert isinstance(x, Sequence) and len(x) == 2\n",
        "        return [tuple[p] for p in padding]\n",
        "\n",
        "\n",
        "def resize_with_aligned_corners(\n",
        "    image: chex.Array,\n",
        "    shape: Sequence[int],\n",
        "    method: str | jax.image.ResizeMethod,\n",
        "    antialias: bool,\n",
        "):\n",
        "    \"\"\"Alternative to jax.image.resize(), which emulates align_corners=True in PyTorch's\n",
        "    interpolation functions.\n",
        "\n",
        "    Copy from https://github.com/google/jax/issues/11206#issuecomment-1423140760\n",
        "    \"\"\"\n",
        "    spatial_dims = tuple(i for i in range(len(shape)) if not jax.core.symbolic_equal_dim(image.shape[i], shape[i]))\n",
        "    scale = jnp.array([(shape[i] - 1.0) / (image.shape[i] - 1.0) for i in spatial_dims])\n",
        "    translation = -(scale / 2.0 - 0.5)\n",
        "    return jax.image.scale_and_translate(\n",
        "        image,\n",
        "        shape,\n",
        "        method=method,\n",
        "        scale=scale,\n",
        "        spatial_dims=spatial_dims,\n",
        "        translation=translation,\n",
        "        antialias=antialias,\n",
        "    )\n",
        "\n",
        "\n",
        "class GlobalConv(linen.Module):\n",
        "    \"\"\"Top branch in IOI module.\"\"\"\n",
        "\n",
        "    features: int\n",
        "    num_frames: int = 16\n",
        "    pos_dim: int = 16\n",
        "    conv: ModuleDef = linen.Conv\n",
        "    norm: ModuleDef = linen.BatchNorm\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array, param: chex.Array) -> chex.Array:\n",
        "        # Temporal focus convolution.\n",
        "        x = x * param\n",
        "        x = self.conv(self.num_frames, kernel_size=(3, 3), padding=to_padding(1), name=\"conv1\")(x)\n",
        "        x = self.norm(name=\"norm1\")(x)\n",
        "        x = linen.relu(x)\n",
        "\n",
        "        # Time encoding\n",
        "        *_, h, w, _ = jnp.shape(x)\n",
        "        x += resize_with_aligned_corners(\n",
        "            self.param(\"pos_embed\", linen.initializers.kaiming_normal(), (self.pos_dim, self.pos_dim, self.num_frames)),\n",
        "            shape=(h, w, self.num_frames),\n",
        "            method=\"bilinear\",\n",
        "            antialias=False,\n",
        "        )\n",
        "\n",
        "        x = self.conv(self.num_frames, kernel_size=(7, 7), padding=to_padding(3), name=\"conv2\")(x)\n",
        "        x = self.norm(name=\"norm2\")(x)\n",
        "        x = linen.relu(x)\n",
        "\n",
        "        x = self.conv(self.features, kernel_size=(3, 3), padding=to_padding(1), name=\"conv3\")(x)\n",
        "        x = linen.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class IOI(linen.Module):\n",
        "    \"\"\"\n",
        "    Inter-temporal object interaction module.\n",
        "    \"\"\"\n",
        "\n",
        "    features: int\n",
        "    num_frames: int = 16\n",
        "    pos_dim: int = 16\n",
        "    conv: ModuleDef = linen.Conv\n",
        "    norm: ModuleDef = linen.BatchNorm\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array, param: chex.Array) -> chex.Array:\n",
        "        # Top branch of IOI module.\n",
        "        x_glo = GlobalConv(\n",
        "            self.features,\n",
        "            num_frames=self.num_frames,\n",
        "            pos_dim=self.pos_dim,\n",
        "            conv=self.conv,\n",
        "            norm=self.norm,\n",
        "            name=\"glo_conv\",\n",
        "        )(x, param)\n",
        "\n",
        "        # Bottom branch of IOI module.\n",
        "        x_short = self.conv(\n",
        "            self.features,\n",
        "            kernel_size=(3, 3),\n",
        "            padding=to_padding(1),\n",
        "            name=\"short_conv\",\n",
        "        )(x)\n",
        "\n",
        "        return x_short * x_glo\n",
        "\n",
        "\n",
        "class ParamConv(linen.Module):\n",
        "    \"\"\"A module that calculates the temporal-adaptive weights.\"\"\"\n",
        "\n",
        "    conv: ModuleDef = linen.Conv\n",
        "    norm: ModuleDef = linen.BatchNorm\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array) -> chex.Array:\n",
        "        in_features = jnp.size(x, axis=-1)\n",
        "        param = einops.reduce(x, \"... h w c -> ... 1 1 c\", \"mean\")\n",
        "        param = self.conv(in_features, kernel_size=(1, 1), use_bias=False, name=\"conv1\")(param)\n",
        "        param = self.norm(name=\"norm1\")(param)\n",
        "        param = linen.relu(param)\n",
        "        param = self.conv(in_features, kernel_size=(1, 1), use_bias=False, name=\"conv2\")(param)\n",
        "        param = linen.sigmoid(param)\n",
        "        return param\n",
        "\n",
        "\n",
        "class CTL(linen.Module):\n",
        "    \"\"\"Channel-Time Learning block.\"\"\"\n",
        "\n",
        "    features: int\n",
        "    num_frames: int = 16\n",
        "    pos_dim: int = 7\n",
        "    kernel_size: int | tuple[int, int] = 1\n",
        "    padding: int = 0\n",
        "    feature_group_count: int = 1\n",
        "    use_bias: bool = True\n",
        "    conv: ModuleDef = linen.Conv\n",
        "    norm: ModuleDef = linen.BatchNorm\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array) -> chex.Array:\n",
        "        # Calculate temporal-adaptive weights\n",
        "        param = ParamConv(conv=self.conv, norm=self.norm, name=\"param_conv\")(x)\n",
        "\n",
        "        # Temporal focus convolution\n",
        "        x_temporal = self.conv(\n",
        "            self.features,\n",
        "            kernel_size=to_2tuple(self.kernel_size),\n",
        "            padding=to_padding(self.padding),\n",
        "            feature_group_count=self.feature_group_count,\n",
        "            use_bias=self.use_bias,\n",
        "            name=\"temporal_conv\",\n",
        "        )(x * param)\n",
        "\n",
        "        x_spatial = IOI(\n",
        "            self.features,\n",
        "            num_frames=self.num_frames,\n",
        "            pos_dim=self.pos_dim,\n",
        "            conv=self.conv,\n",
        "            norm=self.norm,\n",
        "            name=\"spatial_conv\",\n",
        "        )(x, param)\n",
        "\n",
        "        return x_temporal + x_spatial\n",
        "\n",
        "\n",
        "class BasicBlock(linen.Module):\n",
        "    features: int\n",
        "    num_frames: int = 16\n",
        "    stride: int = 1\n",
        "    pos_dim: int = 7\n",
        "    conv: ModuleDef = linen.Conv\n",
        "    norm: ModuleDef = linen.BatchNorm\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array) -> chex.Array:\n",
        "        if self.stride != 1:\n",
        "            assert self.stride == 2\n",
        "            in_features = jnp.size(x, axis=-1)\n",
        "            x = self.conv(\n",
        "                in_features,\n",
        "                kernel_size=(2, 2),\n",
        "                strides=self.stride,\n",
        "                feature_group_count=in_features,\n",
        "                padding=\"VALID\",\n",
        "                name=\"downsample.0\",\n",
        "            )(x)\n",
        "            x = self.norm(name=\"downsample.1\")(x)\n",
        "\n",
        "        # FIXME: pos_dim is not set here in official impl.\n",
        "        # is it a bug?\n",
        "        h = CTL(\n",
        "            self.features,\n",
        "            num_frames=self.num_frames,\n",
        "            # pos_dim=self.pos_dim,\n",
        "            kernel_size=1,\n",
        "            padding=0,\n",
        "            use_bias=False,\n",
        "            conv=self.conv,\n",
        "            norm=self.norm,\n",
        "            name=\"conv1\",\n",
        "        )(x)\n",
        "        h = self.norm(name=\"bn1\")(h)\n",
        "        h = linen.relu(h)\n",
        "\n",
        "        h = CTL(\n",
        "            self.features,\n",
        "            num_frames=self.num_frames,\n",
        "            pos_dim=self.pos_dim,\n",
        "            kernel_size=1,\n",
        "            padding=0,\n",
        "            use_bias=False,\n",
        "            conv=self.conv,\n",
        "            norm=self.norm,\n",
        "            name=\"conv2\",\n",
        "        )(h)\n",
        "        h = self.norm(name=\"bn2\")(h)\n",
        "\n",
        "        if jnp.shape(x) != jnp.shape(h):\n",
        "            x = self.conv(self.features, kernel_size=(1, 1), use_bias=False, name=\"shortcut_conv.0\")(x)\n",
        "            x = self.norm(name=\"shortcut_conv.1\")(x)\n",
        "\n",
        "        y = linen.relu(x + h)\n",
        "        return y\n",
        "\n",
        "\n",
        "class Bottleneck(linen.Module):\n",
        "    features: int\n",
        "    num_frames: int = 16\n",
        "    stride: int = 1\n",
        "    pos_dim: int = 7\n",
        "    expansion: int = 4\n",
        "    conv: ModuleDef = linen.Conv\n",
        "    norm: ModuleDef = linen.BatchNorm\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array) -> chex.Array:\n",
        "        if self.stride != 1:\n",
        "            assert self.stride == 2\n",
        "            in_features = jnp.size(x, axis=-1)\n",
        "            x = self.conv(\n",
        "                in_features,\n",
        "                kernel_size=(2, 2),\n",
        "                strides=self.stride,\n",
        "                feature_group_count=in_features,\n",
        "                padding=\"VALID\",\n",
        "                name=\"downsample.0\",\n",
        "            )(x)\n",
        "            x = self.norm(name=\"downsample.1\")(x)\n",
        "\n",
        "        h = self.conv(self.features, kernel_size=(1, 1), use_bias=False, name=\"conv1\")(x)\n",
        "        h = self.norm(name=\"bn1\")(h)\n",
        "        h = linen.relu(h)\n",
        "\n",
        "        h = CTL(\n",
        "            self.features,\n",
        "            num_frames=self.num_frames,\n",
        "            pos_dim=self.pos_dim,\n",
        "            kernel_size=1,\n",
        "            padding=0,\n",
        "            use_bias=False,\n",
        "            conv=self.conv,\n",
        "            norm=self.norm,\n",
        "            name=\"conv2\",\n",
        "        )(h)\n",
        "        h = self.norm(name=\"bn2\")(h)\n",
        "        h = linen.relu(h)\n",
        "\n",
        "        h = self.conv(self.features * self.expansion, kernel_size=(1, 1), use_bias=False, name=\"conv3\")(h)\n",
        "        h = self.norm(name=\"bn3\")(h)\n",
        "\n",
        "        if jnp.shape(x) != jnp.shape(h):\n",
        "            x = self.conv(self.features * self.expansion, kernel_size=(1, 1), use_bias=False, name=\"shortcut_conv.0\")(x)\n",
        "            x = self.norm(name=\"shortcut_conv.1\")(x)\n",
        "\n",
        "        y = linen.relu(x + h)\n",
        "        return y\n",
        "\n",
        "\n",
        "class ResNet(linen.Module):\n",
        "    \"\"\"SqueezeTime ResNet model.\n",
        "\n",
        "    Attributes:\n",
        "        stage_sizes: Number of blocks in each stage.\n",
        "        block_cls: Residual block class.\n",
        "        num_classes: Number of classes.\n",
        "            If 0, the final dense layer is not added.\n",
        "        num_frames: Number of frames.\n",
        "        drop_rate: Dropout rate.\n",
        "        widen_factor: Width factor.\n",
        "        pos_dims: Positional embedding dimensions.\n",
        "        dtype: Data type for computation.\n",
        "        norm_dtype: Data type for normalization.\n",
        "        param_dtype: Data type for parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    stage_sizes: list[int]\n",
        "    block_cls: ModuleDef\n",
        "    num_classes: int = 400\n",
        "    num_frames: int = 16\n",
        "    drop_rate: float = 0.5\n",
        "    widen_factor: float = 1.0\n",
        "    pos_dims: list[int] = (56, 28, 14, 7)\n",
        "    dtype: chex.ArrayDType = jnp.float32\n",
        "    norm_dtype: chex.ArrayDType = jnp.float32\n",
        "    param_dtype: chex.ArrayDType = jnp.float32\n",
        "\n",
        "    @linen.compact\n",
        "    def __call__(self, x: chex.Array, is_training: bool = False) -> chex.Array:\n",
        "        base_size = int(64 * self.widen_factor)\n",
        "        conv = partial(linen.Conv, dtype=self.dtype, param_dtype=self.param_dtype)\n",
        "        norm = partial(\n",
        "            linen.BatchNorm, use_running_average=not is_training, dtype=self.norm_dtype, param_dtype=self.param_dtype\n",
        "        )\n",
        "\n",
        "        x = einops.rearrange(x, \"... T H W C -> ... H W (C T)\")\n",
        "        x = conv(base_size, kernel_size=(5, 5), strides=2, padding=to_padding(2), use_bias=False, name=\"conv1\")(x)\n",
        "        x = norm(name=\"bn1\")(x)\n",
        "        x = linen.relu(x)\n",
        "        x = linen.max_pool(x, window_shape=(3, 3), strides=(2, 2), padding=to_padding(1))\n",
        "\n",
        "        for i, block_size in enumerate(self.stage_sizes):\n",
        "            for j in range(block_size):\n",
        "                x = self.block_cls(\n",
        "                    features=base_size * 2**i,\n",
        "                    num_frames=self.num_frames,\n",
        "                    stride=2 if i > 0 and j == 0 else 1,\n",
        "                    pos_dim=self.pos_dims[i],\n",
        "                    conv=conv,\n",
        "                    norm=norm,\n",
        "                    name=f\"layer{i+1}.{j}\",\n",
        "                )(x)\n",
        "\n",
        "        x = einops.reduce(x, \"... H W C -> ... C\", \"mean\")\n",
        "        x = linen.Dropout(rate=self.drop_rate, deterministic=not is_training)(x)\n",
        "        if self.num_classes > 0:\n",
        "            x = linen.Dense(self.num_classes, dtype=self.dtype, param_dtype=self.param_dtype, name=\"fc\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet18(**kwargs) -> ResNet:\n",
        "    return ResNet(stage_sizes=[2, 2, 2, 2], block_cls=BasicBlock, **kwargs)\n",
        "\n",
        "\n",
        "def resnet34(**kwargs) -> ResNet:\n",
        "    return ResNet(stage_sizes=[3, 4, 6, 3], block_cls=BasicBlock, **kwargs)\n",
        "\n",
        "\n",
        "def resnet50(**kwargs) -> ResNet:\n",
        "    return ResNet(stage_sizes=[3, 4, 6, 3], block_cls=Bottleneck, **kwargs)\n",
        "\n",
        "\n",
        "def resnet101(**kwargs) -> ResNet:\n",
        "    return ResNet(stage_sizes=[3, 4, 23, 3], block_cls=Bottleneck, **kwargs)\n",
        "\n",
        "\n",
        "def resnet152(**kwargs) -> ResNet:\n",
        "    return ResNet(stage_sizes=[3, 8, 36, 3], block_cls=Bottleneck, **kwargs)\n",
        "\n",
        "\n",
        "def resnet200(**kwargs) -> ResNet:\n",
        "    return ResNet(stage_sizes=[3, 24, 36, 3], block_cls=Bottleneck, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign variables/\n",
        "from torch import nn\n",
        "from einops import rearrange\n",
        "import jax.numpy as jnp\n",
        "from jax import tree_util\n",
        "from flax import traverse_util\n",
        "\n",
        "from mmaction.models.backbones.SqueezeTime import Conv2d as SqueezeTimeConv2d\n",
        "from mmaction.models.backbones.SqueezeTime_ava import Conv2d as SqueezeTimeAvaConv2d\n",
        "\n",
        "\n",
        "def tensor_to_array(tensor):\n",
        "    return jnp.array(tensor.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "def convert_dense(m):\n",
        "    state = tree_util.tree_map(tensor_to_array, m.state_dict())\n",
        "    params = {\"kernel\": rearrange(state[\"weight\"], \"outC inC -> inC outC\")}\n",
        "    if \"bias\" in state:\n",
        "        params[\"bias\"] = state[\"bias\"]\n",
        "    return params, {}\n",
        "\n",
        "def convert_conv(m):\n",
        "    state = tree_util.tree_map(tensor_to_array, m.state_dict())\n",
        "    params = {\"kernel\": rearrange(state[\"weight\"], \"outC inC ... -> ... inC outC\")}\n",
        "    if \"bias\" in state:\n",
        "        params[\"bias\"] = state[\"bias\"]\n",
        "    return params, {}\n",
        "\n",
        "\n",
        "def convert_bn(m):\n",
        "    state = tree_util.tree_map(tensor_to_array, m.state_dict())\n",
        "    params = {}\n",
        "    batch_stats = {}\n",
        "    if \"weight\" in state:\n",
        "        params[\"scale\"] = state[\"weight\"]\n",
        "    if \"bias\" in state:\n",
        "        params[\"bias\"] = state[\"bias\"]\n",
        "    if \"running_mean\" in state:\n",
        "        batch_stats[\"mean\"] = state[\"running_mean\"]\n",
        "    if \"running_var\" in state:\n",
        "        batch_stats[\"var\"] = state[\"running_var\"]\n",
        "    return params, batch_stats\n",
        "\n",
        "\n",
        "def convert_ctl(m):\n",
        "    params = {}\n",
        "    batch_stats = {}\n",
        "\n",
        "    # param conv.\n",
        "    norm_params, norm_batch_stats = convert_bn(m.param_conv[2])\n",
        "    params[\"param_conv\"] = {}\n",
        "    params[\"param_conv\"][\"conv1\"], _ = convert_conv(m.param_conv[1])\n",
        "    params[\"param_conv\"][\"norm1\"] = norm_params\n",
        "    params[\"param_conv\"][\"conv2\"], _ = convert_conv(m.param_conv[4])\n",
        "    if norm_batch_stats:\n",
        "        batch_stats[\"param_conv\"] = {\"norm1\": norm_batch_stats}\n",
        "\n",
        "    # temporal conv.\n",
        "    params[\"temporal_conv\"], _ = convert_conv(m.temporal_conv)\n",
        "\n",
        "    # spatial conv.\n",
        "    params[\"spatial_conv\"] = {}\n",
        "    batch_stats[\"spatial_conv\"] = {}\n",
        "\n",
        "    # short conv in spatial conv.\n",
        "    params[\"spatial_conv\"][\"short_conv\"], _ = convert_conv(m.spatial_conv.short_conv)\n",
        "\n",
        "    # global conv in spatial conv.\n",
        "    glo_conv = m.spatial_conv.glo_conv\n",
        "    glo_params, glo_batch_stats = {}, {}\n",
        "    glo_params[\"conv1\"], _ = convert_conv(glo_conv[0])\n",
        "    glo_params[\"norm1\"], glo_batch_stats[\"norm1\"] = convert_bn(glo_conv[1])\n",
        "    glo_params[\"conv2\"], _ = convert_conv(glo_conv[3])\n",
        "    glo_params[\"norm2\"], glo_batch_stats[\"norm2\"] = convert_bn(glo_conv[4])\n",
        "    glo_params[\"conv3\"], _ = convert_conv(glo_conv[6])\n",
        "\n",
        "    # positional encoding\n",
        "    glo_params[\"pos_embed\"] = rearrange(\n",
        "        tensor_to_array(m.spatial_conv.pos_embed),\n",
        "        \"1 t h w -> h w t\",\n",
        "    )\n",
        "\n",
        "    params[\"spatial_conv\"][\"glo_conv\"] = glo_params\n",
        "    batch_stats[\"spatial_conv\"][\"glo_conv\"] = glo_batch_stats\n",
        "\n",
        "    return params, batch_stats\n",
        "\n",
        "\n",
        "def get_variables_from_torch_model(torch_model: nn.Module):\n",
        "    def f(m):\n",
        "        new_params = {}\n",
        "        new_batch_stats = {}\n",
        "        for name, module in m.named_children():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                params, batch_stats = convert_dense(module)\n",
        "            elif isinstance(module, nn.Conv2d):\n",
        "                params, batch_stats = convert_conv(module)\n",
        "            elif isinstance(module, nn.BatchNorm2d):\n",
        "                params, batch_stats = convert_bn(module)\n",
        "            elif isinstance(module, (SqueezeTimeConv2d, SqueezeTimeAvaConv2d)):\n",
        "                params, batch_stats = convert_ctl(module)\n",
        "            else:\n",
        "                params, batch_stats = f(module)\n",
        "\n",
        "            new_params[name] = params\n",
        "            new_batch_stats[name] = batch_stats\n",
        "        return new_params, new_batch_stats\n",
        "\n",
        "    def remove_empty_dict(d):\n",
        "        y = {}\n",
        "        for k, v in d.items():\n",
        "            if isinstance(v, dict):\n",
        "                if v:\n",
        "                    y[k] = remove_empty_dict(v)\n",
        "            else:\n",
        "                y[k] = v\n",
        "        return y\n",
        "\n",
        "    params, batch_stats = f(torch_model)\n",
        "    params = remove_empty_dict(params)\n",
        "    batch_stats = remove_empty_dict(batch_stats)\n",
        "    return {\"params\": params, \"batch_stats\": batch_stats}\n",
        "\n",
        "\n",
        "def assign_variables_from_torch_model(variables, torch_model):\n",
        "    to_assign = get_variables_from_torch_model(torch_model)\n",
        "    assigned = {}\n",
        "    for key, col in variables.items():\n",
        "        flatten = traverse_util.flatten_dict(to_assign[key], sep=\".\")\n",
        "\n",
        "        new_col = {}\n",
        "        for name_tuple, array in traverse_util.flatten_dict(col).items():\n",
        "            name = \".\".join(name_tuple)\n",
        "            if name in flatten:\n",
        "                assert (\n",
        "                    array.shape == flatten[name].shape\n",
        "                ), f\"Shape mismatch: {name} ({array.shape} vs {flatten[name].shape}).\"\n",
        "                new_col[\"/\".join(name_tuple)] = flatten[name]\n",
        "            else:\n",
        "                raise RuntimeError(f\"{name} is not found from PyTorch model.\")\n",
        "\n",
        "        assigned[key] = traverse_util.unflatten_dict(new_col, sep=\"/\")\n",
        "    return assigned\n"
      ],
      "metadata": {
        "id": "FDPxaeK9pXrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mmaction.apis import init_recognizer\n",
        "\n",
        "def create_torch_model(config_file, checkpoint_file):\n",
        "    torch_model = init_recognizer(config_file, checkpoint_file, device=\"cpu\")\n",
        "\n",
        "    m = torch_model.backbone.net\n",
        "    m.add_module(\"avg_pool\", torch_model.cls_head.avg_pool)\n",
        "    m.add_module(\"fc\", torch_model.cls_head.fc_cls)\n",
        "    return m"
      ],
      "metadata": {
        "id": "1eme7WpBEivx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pickle\n",
        "import numpy\n",
        "import torch\n",
        "import jax\n",
        "import jax.random as jr\n",
        "from einops import rearrange\n",
        "\n",
        "\n",
        "def convert(out_file, config_file, checkpoint_file, num_classes):\n",
        "    flax_model = resnet50(num_classes=num_classes, num_frames=16, pos_dims=(56, 28, 14, 7))\n",
        "    torch_model = create_torch_model(\n",
        "        config_file=config_file,\n",
        "        checkpoint_file=checkpoint_file,\n",
        "    )\n",
        "\n",
        "    input_array = jr.uniform(jr.PRNGKey(0), (1, 16, 224, 224, 3))\n",
        "    input_tensor = torch.from_numpy(numpy.array(input_array))\n",
        "    input_tensor = rearrange(input_tensor, \"b t h w c -> b c t h w\")\n",
        "    input_tensor = input_tensor.contiguous()\n",
        "\n",
        "    # initialize.\n",
        "    variables = flax_model.init(jr.PRNGKey(0), input_array)\n",
        "    variables = assign_variables_from_torch_model(variables, torch_model)\n",
        "\n",
        "    # compute outputs.\n",
        "    output_array = flax_model.apply(variables, input_array)\n",
        "\n",
        "    output_tensor = torch_model(input_tensor)\n",
        "    output_tensor = torch_model.avg_pool(output_tensor)\n",
        "    output_tensor = output_tensor.view(output_tensor.shape[0], -1)\n",
        "    output_tensor = torch_model.fc(output_tensor)\n",
        "    output_tensor = output_tensor.detach().cpu().numpy()\n",
        "    # output_tensor = rearrange(output_tensor, \"b c h w -> b h w c\")\n",
        "\n",
        "    # compare outputs.\n",
        "    print(checkpoint_file)\n",
        "    print(\"=> Max diff.\", jnp.abs(output_array - output_tensor).max())\n",
        "    print(\"=> Avg diff.\", jnp.abs(output_array - output_tensor).mean())\n",
        "\n",
        "\n",
        "    Path(out_file).parent.mkdir(parents=True, exist_ok=True)\n",
        "    variables = jax.tree_util.tree_map(numpy.array, variables)\n",
        "    Path(out_file).write_bytes(pickle.dumps(variables))\n"
      ],
      "metadata": {
        "id": "oRL5ZiSFqLVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert(\n",
        "    \"converted/k400.pkl\",\n",
        "    config_file=\"SqueezeTime/configs/recognition/SqueezeTime/SqueezeTime_K400.py\",\n",
        "    checkpoint_file=\"ckpts/SqueezeTime_K400_71.64.pth\",\n",
        "    num_classes=400,\n",
        "    )\n",
        "\n",
        "convert(\n",
        "    \"converted/k600.pkl\",\n",
        "    config_file=\"SqueezeTime/configs/recognition/SqueezeTime/SqueezeTime_K600.py\",\n",
        "    checkpoint_file=\"ckpts/SqueezeTime_K600_76.06.pth\",\n",
        "    num_classes=600,\n",
        ")\n",
        "\n",
        "convert(\n",
        "    \"converted/hmdb51.pkl\",\n",
        "    config_file=\"SqueezeTime/configs/recognition/SqueezeTime/SqueezeTime_HMDB51.py\",\n",
        "    checkpoint_file=\"ckpts/SqueezeTime_HMDB51_65.56.pth\",\n",
        "    num_classes=51,\n",
        ")"
      ],
      "metadata": {
        "id": "UHU2HzxbK9V-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}